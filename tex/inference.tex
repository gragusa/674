% Copyright © 2013-2014 Gray Calhoun

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\section{Inference and partial identification in SVARs}

\subsection{Simple confidence intervals for VARs}
\subsubsection{Intervals based on asymptotic normality of coefficients}
\begin{itemize}
\item Want confidence intervals associated with these IRFs (draw)
\item $\delta$-method (example for AR(1)):
  \[y_t = \rho y_{t-1} + e_t,\]
  then we know that
  \[  y_{t+k} - y_{t-1} = \rho^k \Delta e_t;\]
  so we'd like to make a confidence region for
\end{itemize}
\[\sqrt{T} (\hat \rho^1 - \rho^1,\dots,\hat \rho^k - \rho^k)\]
for any $j$, $\sqrt{T} (\hat \rho^j - \rho^j) \to N(0, (j \rho^{j-1}) 2 \sigma²)$,
which breaks if $\rho = 0$!

\subsubsection{Problems with these intervals}
\subsubsection{Proposed solutions to these problems}
\subsection{Uniformly valid confidence intervals for VARs}
  \citep{Mik07}, \citep{Mik12}
\subsection{Bayesian intervals}
\begin{itemize}
\item specify prior for AR coefficients and VCV
\item Draw candidate values of the AR coefficients from the posterior
\item For each one, calculate the IRF as before
\item Summarize with mean, mode, or credible set
\item It is \emph{very unlikely} that these are uniformly valid
  credible sets if you use the uniform prior
\end{itemize}

\subsection{Partial identification through sign restrictions.}

The basic idea behind partial identification is that we may not have
enough information to pin down a value precisely, but we might still
be able to derive economically interesting restrictions.  For example,
if we define a set of \emph{potential} ``loose'' monetary policy
shocks to be any innovation that lowers the Federal Funds rate, and
\emph{any} shock that meets that minor condition leads to a rise in
GDP growth, we can conclude that monetary policy shocks cause GDP
growth to rise.

\begin{itemize}
\item The key difference between this approach and the previous
  approaches is that, in this hypothetical example, we don't need to
  know which of the innovations actually line up with monetary policy
  shocks, since we know that (hypothetically) GDP growth has a
  nonnegative response to all of them.
\item Implementation without worrying about inference is relatively
  easy:
  \begin{itemize}
  \item Estimate the reduced-form VAR,
    \[ y_t = \Phi_0 + \sum_{j=1}^p \Phi_j y_{t-j} + e_t \]
    and the variance-covariance matrix of $e_t$ as usual.
  \item Cholesky-decompose $\Sigmah$, so $\Sigmah = PP'$ with $P$ lower
    triangular.
  \item For any orthonormal $D$, $\Sigmah = PP'$ implies that $\Sigmah =
    (PD)(PD)'$, so we're going to proceed as before, but letting
    $A_0^{-1} = PD$ and letting $D$ range over the whole set of
    orthonormal matrices.  ``Range'' means that we'll simulate a bunch of
    orthonormal matrices.

    One way to let $D$ range over these matrices is to draw a $k×k$
    matrix of standard normal random variables, call it $L$, and take
    the QR decomposition of $L$, giving $L=QR$ where $Q$ is
    orthonormal.  Then let $D=Q$.
  \item For each draw of $A_0=(PD)^{-1}$, calculate the IRFs.  If they
    satisfy some economically-motivated constraints, keep that draw of
    $A_0$ (in the brief example above, the constraint would be that the
    Federal Funds rate has an immediate positive response).  Otherwise
    discard it.  Either way, draw many many more candidate values of
    $A_0$.
  \item The set of unrejected $A_0$ defines a set of potential IRFs for
    the economic shock of interest.  Note that there's no way to say
    that one of these IRFs is ``more plausible'' than any others,
    since they all correspond to the exact same value of the
    likelihiood.
  \end{itemize}
\item Bayesian estimation works very nicely with the algorithm
  described above, and makes it computationally easy to account for
  uncertainty in the estimators of $\Phi$ and $\Sigma$.  But we want to be
  careful to not accidentally turn the method for generating candidate
  values of $A_0$ into a prior over different values of $A_0$, which
  will happen if we treat uncertainty over $A_0$ the same as
  uncertainty over the values of $\Phi$ and $\Sigma$.  (Need to add references)
\item I need to add notes and references on handling estimation
  uncertainty for classical estimation and for Bayesian estimation
  when we don't want to impose a prior on $A_0$.
\item Problem with Bayesian inference: naive credible sets are invalid
  as confidence sets.\cite{MS12}.
\item One possibility: conduct inference on the identified set, not
  the parameter value.\cite{KT13}
\end{itemize}

\subsection{Further reading}
\begin{itemize}
\item \citep{Ki13} reviews SVARs in general, with some material on inference and sign restrictions.
\item \citep{FP11} reviews sign restrictions in SVARs.
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../macroeconometrics"
%%% End:
