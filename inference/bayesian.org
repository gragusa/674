Bayesian inference
#+AUTHOR: Gray Calhoun
#+DATE: November 20th, 2014, version \version

* Introduction
** Basics of Bayesian inference (review)
   Suppose we know the data are generated as
   + Prior: $p(\theta)$
   + Likelihood: $p(X \mid \theta)$

   Then after observing the data, we can update the prior
   distribution using Bayes's rule:
   \[
   p(\theta \mid X) = \frac{p(X \mid \theta) p(\theta)}{p(X)}
   \]
   where
   \[
   p(X) = \int p(X \mid \theta) p(\theta) d\theta
   \]
   + This conditional probability is the /posterior density/ of
     $\theta$
   + We can also use this approach even if we don't believe that the
     prior is correct/meaningful
** How can we use the posterior density?
   + *Point estimation*: Often the posterior mean is consistent and asymptotically
     equivalent to the MLE
     \[
     \hat\theta = \int p(\theta \mid X) d\theta
     \]
   + *Confidence sets*: if we let $a$ and $b$ be the $\alpha$ and $1 -
     \beta$ quantiles of $p(\theta \mid X)$, the interval $[a,b]$ is
     often a good $1 - \alpha - \beta$ confidence interval.
** Informal argument for asymptotic normality of posterior
   + Similar to consistency and asymptotic normality of MLE
   + Assume $\theta$ is in a $1/\sqrt{n}$-neighborhood of $\theta_0$
   + Expand log-likelihood around $\theta_0$ (assuming i.i.d. for now)
     \begin{align*}
     \log p(X \mid \theta) &- \log p(X \mid \theta_0) \\
     &= \sum_{i=1}^T (\log p(x_i \mid \theta) - \log p(X \mid \theta_0))\\
     &= \sum_{i=1}^T \tfrac{\partial}{\partial\theta} \log p(x_i \mid \theta_0) (\theta - \theta_0) \\
     &\quad + \tfrac{1}{2} (\theta - \theta_0)' \Big(\sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Big) (\theta - \theta_0) + r
     \end{align*}
     (regularity conditions like you've seen in 672 ensure that $r = o_p(1/n)$ uniformly in relevant values of $\theta$)
** Informal argument for asymptotic normality of posterior
   + This lets us expand the log-posterior around $\theta_0$
     \begin{align*}
     \log p(\theta \mid X) &- \log p(\theta_0 \mid X) \\
     &= \log p(X \mid \theta) - \log p(X \mid \theta_0) - \log p(\theta) + \log p(\theta_0) \\
     &= \sum_{i=1}^T \tfrac{\partial}{\partial\theta} \log p(x_i \mid \theta_0) (\theta - \theta_0) \\
     &\quad + \tfrac{1}{2} (\theta - \theta_0)' \Big(\sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Big) (\theta - \theta_0) \\
     &\quad - \log p(\theta) + \log p(\theta_0) + r
     \end{align*}
** Informal argument for asymptotic normality of posterior
   + Scale by $1/n$:
     \begin{align*}
     \tfrac{1}{n} (\log p(\theta \mid X) &- \log p(\theta_0 \mid X)) \\
     &= \tfrac{1}{n} \sum_{i=1}^T \tfrac{\partial}{\partial\theta} \log p(x_i \mid \theta_0) (\theta - \theta_0) \\
     &\quad + (\theta - \theta_0)' \Big(\tfrac{1}{n} \sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Big) (\theta - \theta_0) \\
     &\quad - \tfrac{1}{n} (\log p(\theta) - \log p(\theta_0) - r) \\
     & \to^p \tfrac{1}{2} (\theta - \theta_0)' \Big(\plim \tfrac{1}{n} \sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Big) (\theta - \theta_0)
     \end{align*}
** Informal argument for asymptotic normality of posterior
   + So in large samples, in a neighborhood of $\theta_0$,
     \begin{multline*}
     \log p(\theta \mid X) \approx \log p(\theta_0 \mid X)) + \\ \tfrac{1}{2} (\theta - \theta_0)' \Big(E \sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Big) (\theta - \theta_0)
     \end{multline*}
   + If $\theta \mid X \sim N(\theta_0, \Sigma)$, we'd have
     \[
     \log p(\theta \mid X) = \mathit{constant} - \tfrac{1}{2} (\theta - \theta_0)' \Sigma^{-1} (\theta - \theta_0)
     \]
     so we have
     \[
     \Sigma \approx  - \Bigg(E \sum_{i=1}^T \tfrac{\partial^2}{\partial\theta^2} \log p(x_i \mid \theta_0)\Bigg)^{-1}
     \]
     which is also what we see in MLE
** Informal argument for asymptotic normality of posterior
   + Informally, in large samples where the MLE is consistent and
     asymptotically normal, the posterior is consistent and
     asymptotically normal as well for any reasonable prior.
   + /Bernstein-von Mises Theorem/ (see van der Vaart, 1998,
     /Asymptotic Statistics/)
   + This "proof" is extremely loose. The real proof isn't difficult,
     but uses more advanced concepts
* Evaluating the posterior
** If this is approximately the same as MLE, why be Bayesian?
   Tight coupling with decision theory
     + Point forecast for $h$-steps ahead:
       \begin{align*}
       \hat y_{T+h} &= \E( y_{T + h} \mid y_1,\dots,y_T) \\
       &= \int \E(y_{T+h} \mid \theta, y_1,\dots,y_{T+h-1}) p(y_{T+h-1} \mid \theta, y_1,\dots,y_{T+h-2}) \dots \\
       &\quad \dots p(y_{T+1} \mid y_1,\dots,y_T, \theta) p(\theta \mid y_1,\dots,y_T) d\theta dy_{T+1} \dots dy_{T+h-1}
       \end{align*}
     + Density forecast for $h$-steps ahead:
       \[
       p_y(y_{T+h} \mid y_1,\dots,y_T)
       \]
     + The same estimator gives you the entire joint distribution of parameters and future observations
     + For MLE, we'd need to construct separate models for point and density forecasts, and would need to explicitly handle estimation uncertainty
** If this is approximately the same as MLE, why be Bayesian?
   Some other reasons
   + Computational convenience
     + Maximizing the likelihood function can be difficult for some problems
     + For Bayesian inference, we can evaluate all of the intergrals
       numerically, which can be done much more easily
     + I'm not sure that I buy this rationale very much...
       + but people who actually have experience using these estimators do!
   + Shrinkage
   + Nuisance parameters
     + /Potentially/ many of the modeling decisions we just worried
       about can be integrated away through judicious choice of prior
     + /Practically/ I haven't seen much research on that
   + Consistent with accumulation of information over time
** Drawbacks of Bayesian approach
   + Some areas are underdeveloped relative to Classical stats
     + HAC covariance matrix adjustment
     + Robustness
     + Nonstationary processes
     + But see recent research by Ulrich Mueller (at Princeton)
   + Appropriate priors should be available, just aren't yet
* Simple examples of Bayesian inference
** The simplest example of Bayesian inference you will ever see
   + $S \sim \mathit{binomial}(n,p)$, so the likelihood is
     \[
       f_S(s) = \binom{n}{p} p^s (1-p)^{n-s}
     \]
   + Say $n = 25$, $S = 20$, then we can plot the likelihood:
     =curve(dbinom(20, 25, x), 0, 1)=

     {{{s}}}
     [[./likelihood1.pdf]]
** The simplest example of Bayesian inference you will ever see
   + $S \sim \mathit{binomial}(n,p)$, so the likelihood is
     \[
       f_S(s) = \binom{n}{s} p^s (1-p)^{n-s}
     \]
   + Now we need a prior density for $p$. Why not uniform?
     \[
     f_p(p) = 1\{p \in [0,1]\}
     \]
   + Now we can treat likelihood as proportional to posterior density.
   + *Conjugate prior* a family of priors is the "conjugate prior" for
     a family of likelihoods if the posterior density is in the same
     family.
   + $\mathit{beta}(a, b)$ is the conjugate prior for the binomial
     family and the corresponding posterior is $\beta(a + s, b + n - s)$
     + Prior is "equivalent" to adding $a$ successes and $b$ failures
       to the dataset
     + $\mathit{uniform}(0,1)$ is the $\mathit{beta}(1,1)$ density
     + Has mean $21 / 27$ in this example
** The simplest example of Bayesian inference you will ever see
   Compare posteriors for $\mathit{beta}(1,1)$, $\mathit{beta}(0,0)$,
   and $\mathit{beta}(10,0)$,

   {{{s}}}

   [[./posteriors1.pdf]]

** To predict number of successes in next 8 draws
   + Prediction is easy. Let $S^*$ be the number of successes in the
     next 5 draws.
   + Use LIE:
     \begin{align*}
     \Pr[S^* = s \mid S] &= \E(\Pr[S^* = s \mid S, p] \mid S) \\
     &= \E(\Pr[S^* = s \mid p] \mid S) \\
     &= \E\Bigg( \binom{8}{s} p^s (1-p)^{8-s} \ \Big|\ S \Bigg) \\
     &= \binom{8}{s} \int_0^1 p^s (1-p)^{8-s} f_p(p \mid S)
     \end{align*}
   + Then we (usually) evaluate the probabilities numerically
     (go to example code)
** Key issues to discuss
   1. Choosing a prior distribution
   2. Working with the posterior numerically
   3. If you find this stuff interesting enough that you want to do
      real research with it, take Stats 544 and (maybe) Stats 644! I
      will teach you just enough to be dangerous in this class.
* Prior distributions
** Basic prior distributions
   + We've already talked about conjugate priors
     + Easy to use
     + Available for some families (binomial, normal, etc)
     + Often one parameterization can be interpreted as "no information"
     + Often unavailable or has other unappealing properties
   + "Uninformative" priors
     + "Flat prior" usually isn't uninformative
     + The "Jeffreys prior" is a mostly uninformative prior designed
       to satisfy some invariance principles
     + "Reference prior" is another (Berger, Bernardo, Sun, 2009)
     + There are even more...
   + "Subjective priors"
     + If you actually know something useful about the system you're
       studying, you can put it into the model as a prior density
     + DSGE models can be used to produce priors
   + Empirical Bayes: why not estimate the parameters of the prior?
** Priors used in time-series
   + We will/may talk about DSGE-based priors in our last class
     meeting
   + First, suppose we have a regression model:
     \[
     y_t = x_t'\beta + e_t
     \]
     where $e_t \mid x_1,\dots,x_T \sim N(0, \sigma)$
   + Conjugate prior for $\beta$ and $\sigma$ is Normal-inverse Gamma.
   + Start with the priors
     \begin{align*}
     \beta \mid \sigma &\sim N(b, \sigma^2 V) \\
     1/\sigma^2 &\sim \textit{gamma}(N, \lambda)
     \end{align*}
     where $b$, $V$, $N$, and $\lambda$ are set by the researcher.
** Priors used in time-series
   + Then we get the posterior
     \begin{align*}
     \beta \mid \sigma, Y  &\sim N(b^*, \sigma^2 V^*) \\
     1/\sigma^2 \mid Y &\sim \textit{gamma}(N + T, \lambda + \lambda^* ) \\
     b^* &= V^*V^{-1} b + V^* \sum_{t=1}^T x_t y_t\\
     V^* &= (V^{-1} + X'X)^{-1} \\
     \lambda^* &= \sum_{t=1}^T (y_t - x_t'\hat\beta)^2 + (\hat\beta - b)' V^{-1}V^* X'X  (\hat\beta - b)
     \end{align*}
   + Interpretation of prior parameters: it's as though we had an
     additional dataset with
     \begin{align*}
     V^{-1} &\approx X'X & N &\text{ observations} \\
     b &\approx \hat\beta & \lambda/N &\approx \hat\sigma^2
     \end{align*}
     $N, \lambda, V^{-1} \to 0$ is "noninformative"
** Priors used for time-series
   + Same prior is used for AR(p) and VAR(p)
     + Normal-inverse Gamma is conjugate prior for AR(p) too
     + Normal-inverse Wishart is conjugate prior for VAR(p)
     + Wishart is a multivariate version of the gamma
   + "Litterman prior" for a VAR
     + Normal-inverse Wishart
     + Diffuse prior for constant terms
     + For lags of the same variable
       + Coefficient on first lag: $N(1, \gamma^2)$
       + Coefficient on $j$th lag ($j > 1$): $N(0, (\gamma/j)^2)$
     + For lags of different variables (eq $k$, variable $i$)
       + $j$th lag: $N(0, w \gamma \tau_i / j \tau_k)$
       + has a correction for variances of different series
       + $w$ is a tuning parameter (can be estimated)
     + If series is already differenced (i.e. GDP growth vs. GDP), use
       0 for the first lag as well
** Last slide for priors used for time-series
   + How do we deal with stationarity more generally?
   + Often people don't, or just truncate coefficients to ensure
     stationarity
   + There are some papers that look at potentially nonstationary
     priors: Phillips (1991), Berger and Yang (1994), but not many
* Simulating from posterior
** Need for simulations
   + Even in our simplest example, the easiest way to work with the
     posterior is to simulate from it
   + Most quantities can be expressed as expectations:
     \[
     \Pr[\theta \leq c \mid \textit{data}] = E(1\{\theta \leq c\} \mid \textit{data})
     \]
   + Bayes's theorem gives us a formula for the density function, not
     necessarily a good way to directly generate ovservations
   + Conjugate priors help here
   + We'll cover simulation abstractly and briefly today, more after break
** Rejection sampling
   Suppose we can generate data from $f$, but want to generate data
   from $g$.
   
   If there is a $c$ s.t. $g(x) \leq c f(x)$ for all $x$, we can use
   the Accept-Reject algorithm:
   1) Generate a candidate $x$ from $f$
   2) With probability $g(x) / c f(x)$, accept this value of
      $x$. Otherwise, go back to step 1.

   When it's available, this can work great. Existance of this $c$ is
   not always guaranteed, and even if it is, finding it can be hard.
** Importance sampling
   Suppose we can generate data from $f$, but want to generate data
   from $g$ to calculate the expected value of some $h(X)$ with $X
   \sim g$.
   * Generate $x_1,\dots,x_n$ from $f$. Then
     \[
       h(X) \approx \sum_{i=1}^n h(x_i) g(x_i)/f(x_i)
     \]
   * Why? 
     \begin{align*}
       \sum_{i=1}^n h(x_i) g(x_i)/f(x_i) &\xrightarrow_{n \to \infty} E h(X) g(X)/f(X) \\
       &= \int h(x) \tfrac{g(x)}{f(x)} f(x) dx \\
       &= \int h(x) g(x) dx
     \end{align*}
   * Doing this naively can be _very_ inefficient.
* Conclusion
** Next week (after Thanksgiving break)
   + MCMC (more simulation tools)
   + State Space models
   + DSGE models
   + _Have fun!_
* End matter
** License and copying
   Copyright (c) 2013-2014 Gray Calhoun. Permission is granted to copy,
   distribute and/or modify this document under the terms of the GNU
   Free Documentation License, Version 1.3 or any later version
   published by the Free Software Foundation; with no Invariant
   Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of
   the license is included in the file LICENSE.tex and is also
   available online at [[http://www.gnu.org/copyleft/fdl.html]].
** COMMENT slide setup
#+BEAMER_FRAME_LEVEL: 2
#+OPTIONS: toc:nil
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [presentation,fleqn,t,serif,10pt]
#+STARTUP: beamer
#+LaTeX_HEADER: \usepackage{url,microtype,tikz}
#+LaTeX_HEADER: \urlstyle{same}
#+LaTeX_HEADER: \frenchspacing
#+LaTeX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \usepackage[osf]{sourcecodepro}
#+LaTeX_HEADER: \usepackage[charter]{mathdesign}
#+LaTeX_HEADER: \usecolortheme{dove}
#+LaTeX_HEADER: \usemintedstyle{pastie}
#+LaTeX_HEADER: \DisableLigatures{family = tt*}
#+LaTeX_HEADER: \setbeamertemplate{navigation symbols}{}
#+LaTeX_HEADER: \setbeamertemplate{items}[circle]
#+LaTeX_HEADER: \setbeamerfont{sec title}{parent=title}
#+LaTeX_HEADER: \setbeamercolor{sec title}{parent=titlelike}
#+LaTeX_HEADER: \setbeamerfont{frametitle}{size=\normalsize}
#+LaTeX_HEADER: \setbeamertemplate{frametitle}{\vspace{\baselineskip}\underline{\insertframetitle\vphantom{g}}}
#+LaTeX_HEADER: \setbeamertemplate{itemize/enumerate body begin}{\setlength{\leftmargini}{0pt}}
#+LaTeX_HEADER: \setbeamertemplate{enumerate item}{\insertenumlabel.}
#+LaTeX_HEADER: \setbeamertemplate{enumerate subitem}{\insertenumlabel.\insertsubenumlabel.}
#+LaTeX_HEADER: \setbeamertemplate{enumerate subsubitem}{\insertenumlabel.\insertsubenumlabel.\insertsubsubenumlabel.}
#+LaTeX_HEADER: \setbeamertemplate{enumerate mini template}{\insertenumlabel}
#+LaTeX_HEADER: \input{../VERSION.tex}
#+LaTeX_HEADER: \input{../tex/macros.tex}

#+MACRO: s \vspace{\baselineskip}
